<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Bounding Volume Hierarchy :: My Solar Shading</title>
    <link rel="canonical" href="https://feelpp.github.io/solar-shading/solar-shading/bvh.html">
    <meta name="generator" content="Antora 3.1.3">
    <link rel="stylesheet" href="../_/css/site.css">
<link rel="icon" href="../_/img/favicon.ico" type="image/x-icon">
<script>!function(l,p){if(l.protocol!==p&&l.host=="docs.antora.org"){l.protocol=p}else if(/\.gitlab\.io$/.test(l.host)){l.replace(p+"//docs.antora.org"+l.pathname.substr(l.pathname.indexOf("/",1))+l.search+l.hash)}}(location,"https:")</script>

<script src="../_/js/vendor/tabs-block-extension.js"></script>
<script src="../_/js/vendor/tabs-block-behavior.js"></script>




<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  messageStyle: "none",
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\\[','\\]']],
    processEscapes: true,
    processEnvironments: true,
    ignoreClass: "nostem|nolatexmath"
  },
  asciimath2jax: {
    delimiters: [["\\$", "\\$"]],
    ignoreClass: "nostem|noasciimath"
  },

  TeX: {
      Macros: {
      RR: "{\\mathbb R}",
      NN: "{\\mathbb N}",
      Nso: "{N_{\\mathrm{so}}}",
      Nma: "{N_{\\mathrm{ma}}}",
      Nno: "{N_{\\mathrm{no}}}",
      Ne: "{N_{\\mathrm{e}}}",
      Ilag: ["{\\mathcal{I}^{\\mathrm{lag}}_{#1}}",1],
      calTh: "{\\mathcal{T}_h}",
      Ck: ["{\\mathcal{C}^{#1}}",1],
      Pk: ["{\\mathcal{P}^{#1}}",1],
      Qk: ["{\\mathcal{Q}^{#1}}",1],
      Pch: ["{P^{#1}_{c,h}}",1],
      Pcho: ["{P^{#1}_{c,h,0}}",1],
      Qch: ["{Q^{#1}_{c,h}}",1],
      Ich: ["{\\mathcal{I}^{#1}_{c,h}#2}",2],
      poly: ["{\\mathbb{#1}}",1],
      nf: "{n_f}",
      ngeo: "{n_{\\mathrm{geo}}}",
      geo: "{\\mathrm{geo}}",
      card: ["{\\operatorname{card}(#1)}",1],
      dim: ["{\\operatorname{dim}(#1)}",1],
      opdim: "{\\operatorname{dim}}",
      card: ["{\\operatorname{card}(#1)}",1],
      poly: ["{\\mathbb{#1}",1],
      R: ["{\\mathbb{R}^{#1}}",1],
      set: ["{\\left\\{#1\\right\\}}",1],
      diam: "{\\operatorname{diam}}",
      jump: ["{[\\![ #1 ]\\!]}",1],
      Next: "{\\mathrm{n}}",
      essinf: "{\\operatorname{ess}\\, \\operatorname{inf}}",
      tr: "{\\operatorname{tr}}",
      Id: "{\\mathcal{I}}",
      disp: ["{\\mathbf{#1}}",1],
      stresst: ["{\\mathbf{\\sigma(#1)}}",1],
      deformt: ["{\\mathbf{\\varepsilon(#1)}}",1],
      domain: "{\\Omega}",
      prect: ["{\\left\\(#1\\right\\)}",1],
      ds: "",
      bold: ["{\\bf #1}",1],
      p: "{\\mathrm{p}}",
      q:"{\\mathbf{q}}",
      n:"{\\mathbf{n}}",
      T:"{\\mathcal{T}}",
      F:"{\\mathcal{F}}",
      P:"{\\mathcal{P}}",
      v:"{\\mathbf{v}}"
  },
  extensions: ["mhchem.js"] }
});
</script>
<!--<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/MathJax.js?config=TeX-MML-AM_CHTML"></script>-->
<!-- <script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML' async></script> -->
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS_CHTML'>
</script>
<!--<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.6.0/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>-->

<!--<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.css" integrity="sha384-TEMocfGvRuD1rIAacqrknm5BQZ7W7uWitoih+jMNFXQIbNl16bO8OZmylH/Vi/Ei" crossorigin="anonymous">
<script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.9.0/katex.min.js" integrity="sha384-jmxIlussZWB7qCuB+PgKG1uLjjxbVVIayPJwi6cG6Zb4YKq0JIw+OMnkkEC7kYCq" crossorigin="anonymous"></script>-->
<script>var uiRootPath = '../_'</script>

  </head>
  <body class="article">
<header class="header">
    <nav class="navbar navbar-expand-sm bg-dark navbar-dark navbar-template-project" style="border-top: 4px solid #9E9E9E">
        <div class="navbar-brand">
            <div class="navbar-item feelpp-logo">
                <a href="https://feelpp.github.io/solar-shading">My Solar Shading</a>
            </div>
            <button class="navbar-burger" data-target="topbar-nav">
                <span></span>
                <span></span>
                <span></span>
            </button>
        </div>

        <div id="topbar-nav" class="navbar-menu">
            <div class="navbar-end">
                <div class="navbar-item">
                    <a href="https://docs.feelpp.org/">Documentation Reference</a>
                </div>
                <div class="navbar-item">
                    <a class="navbar-brand"  href="https://www.cemosis.fr">
                        <img class="cemosis-logo"  src="../_/img/cemosis-logo.svg" alt="Cemosis logo"/>
                    </a>
                </div>
            </div>
        </div>
    </nav>
</header>
<div class="body">
<div class="nav-container" data-component="solar-shading" data-version="">
  <aside class="nav">
    <div class="panels">
<div class="nav-panel-menu is-active" data-panel="menu">
  <nav class="nav-menu">
    <h3 class="title"><a href="index.html">Feel++ Template Project</a></h3>
<ul class="nav-list">
  <li class="nav-item" data-depth="0">
<ul class="nav-list">
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="index.html">Introduction</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="cmake.html">cmake environment</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="antora.html">antora environment</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="vscode.html">vscode integration</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="githubactions.html">Github Actions</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="rename.html">Renaming the project</a>
  </li>
  <li class="nav-item" data-depth="1">
    <a class="nav-link" href="jupyter.html">Jupyter Notebook</a>
  </li>
  <li class="nav-item" data-depth="1">
    <button class="nav-item-toggle"></button>
    <a class="nav-link" href="rapport.html">Rapport</a>
<ul class="nav-list">
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="introduction.html">Introduction</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="rng.html">Random Number Generator</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="bv.html">Bounding Volumes</a>
  </li>
  <li class="nav-item is-current-page" data-depth="2">
    <a class="nav-link" href="bvh.html">Bounding Volume Hierarchy</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="traversal.html">Traversal Algortihms</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="raytracing.html">Raytracing</a>
  </li>
  <li class="nav-item" data-depth="2">
    <a class="nav-link" href="tools.html">Tools</a>
  </li>
</ul>
  </li>
</ul>
  </li>
</ul>
  </nav>
</div>
<div class="nav-panel-explore" data-panel="explore">
  <div class="context">
    <span class="title">Feel++ Template Project</span>
    <span class="version">default</span>
  </div>
  <ul class="components">
    <li class="component is-current">
      <a class="title" href="index.html">Feel++ Template Project</a>
      <ul class="versions">
        <li class="version is-current is-latest">
          <a href="index.html">default</a>
        </li>
      </ul>
    </li>
  </ul>
</div>
    </div>
  </aside>
</div>
<main class="article">
<div class="toolbar" role="navigation">
  <button class="nav-toggle"></button>
    <a href="index.html" class="home-link"></a>
  <nav class="breadcrumbs" aria-label="breadcrumbs">
  <ul>
    <li><a href="index.html">Feel++ Template Project</a></li>
    <li><a href="rapport.html">Rapport</a></li>
    <li><a href="bvh.html">Bounding Volume Hierarchy</a></li>
  </ul>
</nav>

  
    <div class="edit-this-page"><a href="https://github.com/feelpp/solar-shading/edit/7-add-project-report-to-antora-pages/docs/modules/ROOT/pages/bvh.adoc">Edit this Page</a></div>
  
  <div class="page-downloads">
  <span class="label">Download as</span>
  <ul class="download-options">
    <li>
      <a onclick="print(this)" href="#" data-toggle="tooltip" data-placement="left" title="Print to PDF"
         class="pdf-download">
        <img class="pdf-file-icon icon" src="../_/img/pdf.svg"/> .pdf
      </a>
    </li>
  </ul>
</div>
</div>

  <div class="content">
<aside class="toc sidebar" data-title="Contents" data-levels="2">
  <div class="toc-menu"></div>
</aside>

<article class="doc">
<h1 class="page">Bounding Volume Hierarchy</h1>
<div class="sect1">
<h2 id="_introduction"><a class="anchor" href="#_introduction"></a>1. Introduction</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Ray-Tracing is a well-known method used in many fields. In order to render physically realistic scenes, or in our case mathematical results, numerous rays must be traced to get plausible outcomes. The goal would be to accelerate the light transport simulation thanks to efficient sampling techniques, leveraging hardware architecture, or by rearranging scene primitives into an efficient spatial data structure. Naïvely, we could compute the ray/scene interactions by testing all scene primitives, which is prohibitively expensive since we rely on fine-grained meshes.</p>
</div>
<div class="paragraph">
<p>BVH has become popular in many use cases, in particular when using ray-tracing, for numerous reasons such as:</p>
</div>
<div class="ulist">
<ul>
<li>
<p><strong>predictable memory footprints:</strong> The memory complexity is linearly bounded to the number of scene primitives since each is only referenced once in the tree, so that the BVH contains at most \(2n-1\) nodes for a binary BVH when dealing with \(n\) primitives / leafs. Even in the case of spatial splits where primitives can be referred to multiple times, the number of occurrences can still be controlled to a certain extent.</p>
</li>
<li>
<p><strong>efficient query:</strong> Using a BVH, we can efficiently prune branches that do not intersect a given ray, and thus reduce the time complexity from linear to logarithmic on average. This will be tested in the benchmark sections.</p>
</li>
<li>
<p><strong>scalable construction:</strong> There are various BVH construction algorithms, ranging from very fast algorithms to complex algorithms that provide highly optimized BVHs.</p>
</li>
<li>
<p><strong>dynamic geometry:</strong> since fast BVH construction is available, they are suitable for use with dynamic geometries</p>
</li>
</ul>
</div>
<div class="paragraph">
<p><strong>Quality of a BVH:</strong> The quality of such a structure corresponds to the ray tracing speed in millions of rays cast per second</p>
</div>
<div class="paragraph">
<p><strong>BVH Node:</strong> Contains information such as child node pointers, the number of leaves, and bounding boxes. Hence, the memory consumption of a BVH drastically increases with the scene&#8217;s size growth.</p>
</div>
<div class="sect2">
<h3 id="_definition"><a class="anchor" href="#_definition"></a>1.1. Definition</h3>
<div class="paragraph">
<p>A visual definition of a BVH structure using Axis-Aligned Bounding-Boxes.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/AABBs.png" alt="AABBs">
</div>
</div>
<div class="paragraph">
<p>In this context, <code>N1</code> would be the bounding volume for the entire object or scene, <code>N2</code> and <code>N3</code> would be those respectively containing <code>N4</code> and <code>N5</code>, and so on, until we reach the leaves of the tree, which are directly the bounding boxes of the primitives.</p>
</div>
</div>
<div class="sect2">
<h3 id="_objectives"><a class="anchor" href="#_objectives"></a>1.2. Objectives</h3>

</div>
</div>
</div>
<div class="sect1">
<h2 id="_construction_methods"><a class="anchor" href="#_construction_methods"></a>2. Construction Methods</h2>
<div class="sectionbody">
<div class="imageblock">
<div class="content">
<img src="_images/constructmet.png" alt="constructmet" width="500">
</div>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/constructmetbis.png" alt="constructmetbis" width="500">
</div>
</div>
<div class="sect2">
<h3 id="_recursive_top_down_construction"><a class="anchor" href="#_recursive_top_down_construction"></a>2.1. Recursive Top-Down Construction</h3>
<div class="paragraph">
<p>In the code snippet below, written by Luca Berti, a recursive top-down construction algorithm was proposed for further improvements. We can see that he adopts a recursive build function, which is called to create each node of the tree: if there is only one primitive, then a leaf is build, else, an internal node is created and the build function is called recursively on the left and right child nodes. Here is the proposed implementation:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-cpp hljs" data-lang="cpp">    BVHNode * recursiveBuild(BVHNode * current_parent, int cut_dimension, int start_index_primitive, int end_index_primitive, std::vector&lt;int&gt; &amp;orderedPrims)
    {
        LOG(INFO) &lt;&lt;fmt::format("cut dimension {}, start index primitive {}, end index primitive {}",cut_dimension,start_index_primitive,end_index_primitive);
        Eigen::VectorXd M_bound_min_node(nDim),M_bound_max_node(nDim);
        BVHNode * node = new BVHTree::BVHNode();
        M_bound_min_node = M_primitiveInfo[start_index_primitive].M_bound_min;
        M_bound_max_node = M_primitiveInfo[start_index_primitive].M_bound_max;
        for (int i = start_index_primitive+1; i &lt; end_index_primitive; ++i)
		{
            M_bound_min_node = node-&gt;newBoundsMin(M_bound_min_node,M_primitiveInfo[i].M_bound_min);
            M_bound_max_node = node-&gt;newBoundsMax(M_bound_max_node,M_primitiveInfo[i].M_bound_max);
        }
        auto mid = (start_index_primitive + end_index_primitive) / 2;
        std::nth_element(&amp;M_primitiveInfo[start_index_primitive], &amp;M_primitiveInf[mid], &amp;M_primitiveInfo[end_index_primitive-1]+1,
        [cut_dimension](const BVHPrimitiveInfo &amp;a, const BVHPrimitiveInfo &amp;b)
		{
            return a.M_centroid[cut_dimension] &lt; b.M_centroid[cut_dimension];
        });
        int nPrimitives = end_index_primitive - start_index_primitive;
        if (nPrimitives == 1)
        {
            // Create a leaf, since there is only one primitive in the list
            int firstPrimOffset = orderedPrims.size();
            for (int i = start_index_primitive; i &lt; end_index_primitive; ++i)
            {
            int primNum = M_primitiveInfo[i].M_primitiveNumber;
            orderedPrims.push_back(primNum);
            }
            node-&gt;buildLeaf(current_parent,firstPrimOffset, nPrimitives, M_bound_min_node,M_bound_max_node);
            return node;
        }
        else{
            // Create a node, since there are at least two primitives in the list
            node-&gt;buildInternalNode(current_parent,(cut_dimension+1)%nDim,
                                    recursiveBuild( node, (cut_dimension+1)%nDim, start_index_primitive, mid, orderedPrims),
                                    recursiveBuild( node, (cut_dimension+1)%nDim, mid, end_index_primitive, orderedPrims));
        }
        return node;
    }</code></pre>
</div>
</div>
<div class="paragraph">
<p>This function is responsible for constructing the BVH tree from the primitives. It&#8217;s called recursively and each time it either creates a leaf node if there&#8217;s only one primitive left, or an internal node with two child nodes. The primitives are split by choosing a cutting dimension and sorting them by their centroids along this dimension, and then the data is divided into two equally sized parts, for each of which a new node is created.</p>
</div>
<div class="paragraph">
<p>The cutting dimension is cycled between 0, 1, 2 (representing the x, y, and z axes in a 3D space) by using <code>(cut_dimension+1)%nDim</code> in the recursive calls. This is the main "Divide and Conquer" idea behind this top-down construction algorithm.</p>
</div>
<div class="paragraph">
<p>It then sorts the primitives by their centroids along the cutting dimension, using the <code>std::nth_element</code> function, which partially sorts the primitives so that the element at the mid index will be in the place it would be in a fully sorted array, and all elements before it are less than or equal to the elements after it. The comparison function <code>[cut_dimension](const BVHPrimitiveInfo &amp;a, const BVHPrimitiveInfo &amp;b) { return a.M_centroid[cut_dimension] &lt; b.M_centroid[cut_dimension]; }</code> is used to sort the elements based on their centroids along the cutting dimension.</p>
</div>
<div class="paragraph">
<p>Finally, the data is divided into two equally sized parts when calculating the midpoint of the primitives' indexes.</p>
</div>
<div class="paragraph">
<p>Other splitting algorithms can be used, such as the Surface Area Heuristic (SAH) or the Middle Split Heuristic (MSH), which are listed and explained in the <a href="#_spatial_splits">Spatial Splits</a> section.</p>
</div>
</div>
<div class="sect2">
<h3 id="_bottom_up_construction"><a class="anchor" href="#_bottom_up_construction"></a>2.2. Bottom-Up Construction</h3>
<div class="paragraph">
<p>Instead of starting with all scene primitives in one cluster and recursively splitting them, bottom-up construction algorithms start with each primitive in its own cluster and recursively merge the closest pairs. This is done either until the desired number of clusters is reached, or each cluster contains a maximum number of primitives. The clusters are then used as the primitives for the next level of the tree. This process is repeated until the root node is reached.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>ADD COMPLETE DEFINITION AND WHY IT WONT BE USED</pre>
</div>
</div>
<div class="paragraph">
<p>Below is an example of a bottom-up construction algorithm:</p>
</div>
<div class="paragraph">
<p>Introduced by Walter et al., bottom-up construction by agglomerative clustering proposes to start with all scene primitives considered as individual clusters and recursively merges the closest pairs (the distance function being for example the surface area of a bounding box enclosing both clusters). In general, these trees tend to have lower global costs, but the construction is more time-consuming.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_clustering"><a class="anchor" href="#_clustering"></a>3. Clustering</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_agglomerative_clustering"><a class="anchor" href="#_agglomerative_clustering"></a>3.1. Agglomerative Clustering</h3>
<div class="paragraph">
<p>The major inconvenience when using bottom-up algorithms is that the upper nodes are poorly locally optimized and thus the research for the closest neighbor can be very costly. To prevent this, Gu et al proposed to recursively perform spatial median splits based on Morton codes until each subtree contains less than a chosen number of clusters. The clusters are merged using agglomerative clustering. Using this at all levels in the BVH, even the top level nodes' split will be locally optimized.</p>
</div>
<div class="paragraph">
<p>Meister and Bittner proposed a GPU-based algorithm using k-means clustering: scene primitives are subdivided into k clusters using k-means clustering. When done recursively, a k-ary BVH is built, which can also be converted to a binary tree by constructing intermediate levels using agglomerative clustering.</p>
</div>
</div>
<div class="sect2">
<h3 id="_parallel_locally_ordered_clustering_on_gpu"><a class="anchor" href="#_parallel_locally_ordered_clustering_on_gpu"></a>3.2. Parallel locally-ordered clustering on GPU</h3>
<div class="paragraph">
<p>Introduced by Meister and Bittner, the key observation is that the distance functions have a non-decreasing property, meaning that once we found two mutually corresponding nearest neighbors, we can immediately merge their clusters since no other closer one will be found. The clusters are kept sorted along the Morton Curve, finding the nearest cluster by searching both sides of the sorted cluster array, testing a predefined number of clusters. Since it does not rely on distance matrices, it is GPU-friendly, and only a small number of iterations are needed to build the whole tree.</p>
</div>
</div>
<div class="sect2">
<h3 id="_linear_bvh_lbvh"><a class="anchor" href="#_linear_bvh_lbvh"></a>3.3. Linear BVH (LBVH)</h3>
<div class="paragraph">
<p>The hierarchical nature of the BVH prevents a straightforward parallelization of the construction algorithm. But now, the BVH construction can be reduced to sorting scene primitives along the Morton curve (the order is given by Morton codes of fixed length, 32 or 64 bits), and using optimized sorting algorithms such as the radix sort, it can be done in 2n-1 time. The Morton code implicitly encodes a BVH constructor by spatial median splits.</p>
</div>
</div>
<div class="sect2">
<h3 id="_morton_curves"><a class="anchor" href="#_morton_curves"></a>3.4. Morton Curves</h3>
<div class="listingblock">
<div class="content">
<pre>ADD EXPLANATION ON MORTON CODE AND CURVES</pre>
</div>
</div>
<div class="admonitionblock note">
<table>
<tr>
<td class="icon">
<i class="fa icon-note" title="Note"></i>
</td>
<td class="content">
<div class="paragraph">
<p>Morton Curves</p>
</div>
<div class="paragraph">
<p>Morton curves map multidimensional data to one dimension while preserving the locality of the data points. They can be considered as a special 1-dimensional path traversing multidimensional data. Displayed below is an example of a Z-order curve (also known as a Morton curve) in a two-dimensional plane.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/morton.png" alt="morton" width="250px">
</div>
</div>
</td>
</tr>
</table>
</div>
<div class="paragraph">
<p>These can be defined thanks to various algorithms presented on
<a href="https://developer.nvidia.com/blog/thinking-parallel-part-iii-tree-construction-gpu/">NVIDIA&#8217;s website</a>.</p>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_construction_optimization"><a class="anchor" href="#_construction_optimization"></a>4. Construction Optimization</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_spatial_splits"><a class="anchor" href="#_spatial_splits"></a>4.1. Spatial Splits</h3>
<div class="paragraph">
<p>Performing the spatial splits in an optimized way is crucial to the performance of the BVH. In fact, this is deeply related to the BVH&#8217;s layout, which is the way the BVH is stored in memory, hence having a strong impact on it&#8217;s construction time, the resulting quality of the BVH, and the traversal performance. The first step is to choose the splitting algorithm, and more importantly the separating axes.</p>
</div>
<div class="sect3">
<h4 id="_longest_axis"><a class="anchor" href="#_longest_axis"></a>4.1.1. Longest Axis</h4>
<div class="paragraph">
<p>One straightforward approach is to choose the axis with the longest extent of the bounding volume as the separating axis. This can help effectively divide the scene along its largest dimension, potentially leading to more balanced partitions.</p>
</div>
</div>
<div class="sect3">
<h4 id="_axis_cycling"><a class="anchor" href="#_axis_cycling"></a>4.1.2. Axis Cycling</h4>
<div class="paragraph">
<p>Another method involves cycling through the three axes (X, Y, Z) and selecting the next axis in a cyclic manner for each spatial split. This approach ensures that the splitting axes are evenly distributed and can help maintain overall balance in the BVH construction.  This is the approach proposed by Luca Berti, presented in the original code of this project, like seen during the call to the recursive build function:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/codesnippet.png" alt="codesnippet">
</div>
</div>
<div class="paragraph">
<p>The 2nd value representing the cutting dimension is cycled between 0, 1 and 2, representing the x, y and z axes of our 3 dimensional euclidean space, by using <code>(cut_dimension+1)%nDim</code> in the recursive calls. At each call, it is incremented by 1, enabling a different splitting axis to be used at <strong>each level</strong> of the tree. After choosing the splitting axis, the median value along that axis is computed and used as the splitting position, also know as a median cut, discussed right below.</p>
</div>
</div>
<div class="sect3">
<h4 id="_median_cut"><a class="anchor" href="#_median_cut"></a>4.1.3. Median Cut</h4>
<div class="paragraph">
<p>The median cut strategy involves computing the median value along a specific axis and using it as the splitting position. This method aims to divide the scene into two halves containing an equal number of objects, which can help achieve good load balancing. This is implemented in the following line of the recursive build method, when calling the <code>std::nth_element</code> function:</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/mediancut.png" alt="mediancut" width="800px">
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_cost_functions"><a class="anchor" href="#_cost_functions"></a>4.2. Cost Functions</h3>
<div class="paragraph">
<p>The quality of a particular BVH can be estimated in terms of the expected number of operations needed for finding the nearest intersection with a given ray. It can be estimated thanks to the recurrence equation:</p>
</div>
<div class="stemblock">
<div class="content">
\[c(N)=
\begin{cases}
c_{T}+\sum_{N_c}{P(N_{c}|N)c(N_{c})} &amp; c_{I}|N|
\end{cases}\]
</div>
</div>
<div class="sect3">
<h4 id="_surface_area_heuristic_sah"><a class="anchor" href="#_surface_area_heuristic_sah"></a>4.2.1. Surface Area Heuristic (SAH)</h4>
<div class="paragraph">
<p>As mentioned earlier, the SAH criterion can also be used to determine the separating axis. It evaluates the cost of each axis based on the surface area of the resulting bounding volumes and chooses the axis with the lowest cost.</p>
</div>
<div class="paragraph">
<p>Using the <strong>surface area heuristic (SAH)</strong>, we can express the conditional probabilities as geometric ones, using their respective surface area to compute the ratio of the surface areas of a child node and the parent&#8217;s one:</p>
</div>
<div class="stemblock">
<div class="content">
\[P(N_{c}|N)^{SAH} = \frac{Area(N_c)}{Area(N)}\]
</div>
</div>
<div class="paragraph">
<p>And finally, assuming that the ray origins and directions are uniformly distributed, after unrolling we get:</p>
</div>
<div class="stemblock">
<div class="content">
\[c(N)^{SAH} = \frac{1}{Area(N)} (c_T \sum_{N_i}Area(N_i) + c_i \sum_{N_l}Area(N_l)|N_l|)\]
</div>
</div>
<div class="paragraph">
<p>Where \(N_i\) and \(N_l\)  respectively denote interior and leaf nodes of a subtree with root \(N\).
The problem of finding an optimal BVH is believed to be NP-hard. But these assumptions are unrealistic and thus several corrections have been proposed.</p>
</div>
<div class="listingblock">
<div class="content">
<pre>ADD BENCHMARKS WHEN IMPLEMENTED</pre>
</div>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_parallelization"><a class="anchor" href="#_parallelization"></a>4.3. Parallelization</h3>
<div class="sect3">
<h4 id="_parallel_on_demand_construction_algorithm"><a class="anchor" href="#_parallel_on_demand_construction_algorithm"></a>4.3.1. Parallel on-demand construction algorithm</h4>
<div class="paragraph">
<p>Introduced by Vinkler et al., it&#8217;s a parallel on-demand construction on the GPU, building only those parts that are visited during the traversal. Since we are using static geometries to compute our shading masks, the BVH should only be built once and used for several traversals. Despite its logical simplicity, it would be great being able to leverage the different memories available on the GPU to store the BVH in a more efficient way, for example on the constant memory, which is a high performance read-only memory. The storage methods will be discussed in the <a href="#_bvh_layout">BVH Layout</a> section.</p>
</div>
</div>
<div class="sect3">
<h4 id="_parallelization_of_the_construction_algorithm"><a class="anchor" href="#_parallelization_of_the_construction_algorithm"></a>4.3.2. Parallelization of the construction algorithm</h4>
<div class="listingblock">
<div class="content">
<pre>ADD EXPLANATION ON HOW TO PARALLELIZE THE CONSTRUCTION ALGORITHM AND SHOW IMPLEMENTATION</pre>
</div>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_bvh_layout"><a class="anchor" href="#_bvh_layout"></a>5. BVH Layout</h2>
<div class="sectionbody">
<div class="sect2">
<h3 id="_wide_bvhs"><a class="anchor" href="#_wide_bvhs"></a>5.1. Wide BVHs</h3>
<div class="listingblock">
<div class="content">
<pre>ADD PROPER DEFINITION OF WIDE BVHs</pre>
</div>
</div>
<div class="paragraph">
<p>BVHs poorly adapt to scenes with overlapping primitives of non-uniform sizes, typically difficult to separate.</p>
</div>
<div class="paragraph">
<p>The use of wide BVHs implies efficient memory usage as they contain significantly fewer interior nodes than binary ones, but this also induces leveraging parallel computing resources using SIMD/SIMT (single instruction multiple data / threads) units by testing one ray against multiple bounding volumes simultaneously during the traversal.</p>
</div>
<div class="paragraph">
<p>There are two classes of algorithms for building wide BVHs. The first class relies on an already existing binary BVH, which is converted to a wide BVH by discarding interior nodes. The second class directly builds a wide BVH during construction. These will not be discussed here.</p>
</div>
</div>
<div class="sect2">
<h3 id="_compact_representation_for_memory_savings"><a class="anchor" href="#_compact_representation_for_memory_savings"></a>5.2. Compact Representation for Memory Savings</h3>
<div class="paragraph">
<p>The memory footprint of a BVH (Bounding Volume Hierarchy) grows substantially with the expansion of the scene&#8217;s scale. This can give rise to significant complications when executing traversal algorithms on memory-constrained GPUs, which possess limited memory resources at their disposal. In order to address this issue, we can try minimizing the information&#8217;s size contained in each node, such as compressing complex geometric data using bounding boxes and vertex coordinates with reduced precision or even representing mesh triangle connectivity using triangle strips.</p>
</div>
<div class="exampleblock tip">
<div class="content">
<div class="paragraph">
<p>Triangle Strips</p>
</div>
<div class="paragraph">
<p>Triangle strips refer to a method used for simplifying the representation of polygonal meshes. In order to reduce the computational costs, better management of the mesh data can lead to significant efficiency improvements. A triangle strip is a series of connected triangles that share vertices, allowing for more efficient memory usage. By storing the shared vertices of these connected triangles, the overall number of vertices needed to define the triangles can be significantly reduced, hence rendering more efficiently and using less memory.</p>
</div>
</div>
</div>
<div class="sect3">
<h4 id="_reduced_precision"><a class="anchor" href="#_reduced_precision"></a>5.2.1. Reduced Precision</h4>
<div class="paragraph">
<p>One way of reducing precision would be the use of <strong><strong>Hierarchical Mesh Quantization</strong></strong>, using a single unified data structure for the BVH&#8217;s <strong>and</strong> triangle&#8217;s storage, achieving a high compression rate by quantizing each vertex of the triangle in a leaf node as a local offset of the leaf bounding box.</p>
</div>
</div>
<div class="sect3">
<h4 id="_triangle_connectivity"><a class="anchor" href="#_triangle_connectivity"></a>5.2.2. Triangle Connectivity</h4>
<div class="paragraph">
<p>Ray-Strips use a two-level data structure (meaning, for example, that one type of data structure is used as the Top-Level Acceleration Structure, each leaf containing, for example, strips or another BVH). Several algorithms can be used to generate the strips (SAH-aware generator such as Strip-RT, generating longer strips with higher spatial coherence, HMQ compresses vertex connectivity by storing short indexed strips containing up to a certain threshold of triangles in each leaf node).</p>
</div>
</div>
</div>
<div class="sect2">
<h3 id="_the_trees_storage_format"><a class="anchor" href="#_the_trees_storage_format"></a>5.3. The Tree&#8217;s Storage Format</h3>
<div class="paragraph">
<p>After successfully constructing the tree in an optimized way, it is important to note that both optimizing the traversal code and the tree&#8217;s representation itself are very important to see an increase in performance. Two obvious ways of dealing with that are to minimize the size of the data structures involved and to rearrange the data in a more cache-friendly way to reduce time for the search of relevant information (for example, it would be better to structure the array holding the pointers in such a way to minimize the time spent during traversal).</p>
</div>
<div class="sect3">
<h4 id="_array_representation"><a class="anchor" href="#_array_representation"></a>5.3.1. Array Representation</h4>
<div class="paragraph">
<p>Let&#8217;s look at a natural way of structuring the tree by mapping its nodes in a breadth-first level-by-level manner:</p>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-c++ hljs" data-lang="c++">// First Level
array[0] = *(root);
// Second level
array[1] = *(root-&gt;left);
array[2] = *(root-&gt;right);
// Third level
array[3] = *(root-&gt;left-&gt;left);</code></pre>
</div>
</div>
<div class="paragraph">
<p>This way, we always know that a parent&#8217;s children can be found at positions \(2i+1\) and \(2i+2\) in the array, usually inducing wasted memory unless dealing with a complete tree.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/arrayrep.png" alt="400">
</div>
</div>
</div>
<div class="sect3">
<h4 id="_preorder_traversal_order"><a class="anchor" href="#_preorder_traversal_order"></a>5.3.2. Preorder Traversal Order</h4>
<div class="paragraph">
<p>When preordering them in traversal order, the left child will always follow its parent, and only one link is needed to point to the right child.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/preordertraversal.png" alt="400">
</div>
</div>
<div class="listingblock">
<div class="content">
<pre class="highlightjs highlight"><code class="language-c++ hljs" data-lang="c++">// Given a tree t, outputs its nodes in preorder traversal order
// into the node array n. Call with i = 0.
int PreorderOutput(Tree *t, Tree n[], int i)
	{
	// Implement a simple stack of parent nodes.
	// Note that the stack pointer ‘sp’ is automatically reset between calls
	const int STACK_SIZE = 100;
	static int parentStack[STACK_SIZE];
	static int sp = 0;
	// Copy over contents from tree node to PTO tree
	n[i].nodeData = t-&gt;nodeData;
	// Set the flag indicating whether there is a left child
	n[i].hasLeft = t-&gt;left != NULL;
	// If node has a right child, push its index for backpatching
	if (t-&gt;right) {
		assert(sp &lt; STACK_SIZE);
		parentStack[sp++] = i;
	}
	// Now recurse over the left part of the tree
	if (t-&gt;left)
		i = PreorderOutput(t-&gt;left, n, i + 1);
	if (t-&gt;right) {
		// Backpatch the right-link of the parent to point to this node
		int p = parentStack[--sp];
		n[p].rightPtr = &amp;n[i + 1];
		// Recurse over the right part of the tree
		i = PreorderOutput(t-&gt;right, n, i + 1);
	}
	// Return the updated array index on exit
	return i;
}</code></pre>
</div>
</div>
<div class="paragraph">
<p>Flattening the tree in this way allows us to store the tree in a single array, with each node containing a pointer to its right child and a flag indicating whether it has a left child or not. This way, we can easily traverse the tree by following the right child pointers and using the left child flags to determine whether we should follow the left child or not and avoid the need for a stack and storage of 2 pointers per node (only one is necessary). This method is also cache-friendly since the nodes are stored in a linear array.</p>
</div>
</div>
<div class="sect3">
<h4 id="_cache_friendly_structures"><a class="anchor" href="#_cache_friendly_structures"></a>5.3.3. Cache-friendly Structures</h4>
<div class="paragraph">
<p>When using modern architecture, execution time is mostly limited by cache issues when fetching data from memory. One possible way of adopting a cache-friendlier solution would be by merging the sets of binary tree nodes into a 'tri-node' containing the parent and its children, preventing it from needing internal links. Below we can see an example representing a complete 4-level binary tree with 14 internal links with a 2-level tri-node tree storing only 4 internal links. Even better, this representation can also be combined with other optimizing structures seen before.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/cachefriendly.png" alt="600">
</div>
</div>
<div class="paragraph">
<p>Flattening a tri-node tree is similar to flattening a binary tree, except that we need to store the parent&#8217;s index in the array as well as the left and right child flags. The right child pointer is replaced by a flag indicating whether the parent has a right child or not, the left and parent&#8217;s one are replaced in the same manner. The root node is a special case, since it has no parent, signified by a special flag. Three new structures (<code>GPUNode</code>, <code>GPURay</code> and <code>GPUTree</code>) were introduced, storing only critical information for it to be of small enough size to be copied-by-value to the GPU.</p>
</div>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_leveraging_ray_locality"><a class="anchor" href="#_leveraging_ray_locality"></a>6. Leveraging Ray Locality</h2>
<div class="sectionbody">
<div class="paragraph">
<p>Spatial data structures exploit the spatial locality of scene primitives. But this isn&#8217;t the only way of leveraging spatial locality. To further accelerate the whole process, we could map rays to interior nodes deeper in the tree, skipping top-level nodes. A major caveat of such methods is that there is no guarantee that the found intersection corresponds to the closest one. But when computing shading masks, the lack of distance consideration is not a drawback. Instead, we solely focus on determining whether an object is present along the path of the ray.</p>
</div>
<div class="paragraph">
<p>Another way to optimize the ray generation would be to exploit the graphics card&#8217;s instancing of objects, enabling it to create multiple copies of one object in record time. Benthin and Wald decided that, instead of tracing the rays sequentially, they would generate bounding frusta of coherent rays simultaneously harnessing the potential of a SIMD unit (as many rays in one frustum as the SIMD unit is wide).</p>
</div>
<div class="paragraph">
<p>This could be taken further, by assigning parts of a matrix to a specific block in the GPU, leveraging the constant memory and launching the frustum of rays in the respective direction defined by the block-assigned resulting matrix. This way, the rays are processed in a more coherent manner, and the GPU&#8217;s constant memory is used to its full potential. Moreover, the frustum could be instantiated directly on the GPU, and the identical rays could be transformed and translated through random values, generated by the mersene twister algorithm that can be implemented on a CUDA kernel, and therefore be naturally processed in parallel. This would result in a more efficient memory transfer, since the rays shouldn&#8217;t be transferred back to the CPU, but only the resulting intersected leaves.</p>
</div>
<div class="imageblock">
<div class="content">
<img src="_images/Nvidia-GPU-memory-structure.png" alt="600">
</div>
</div>
<div class="listingblock">
<div class="content">
<pre>ADD DETAILED EXPLANATION OF THE PROCESS AND STRUCTURES THAT WILL ARE IMPLEMENTED ON GPU</pre>
</div>
</div>
</div>
</div>
<div class="sect1">
<h2 id="_conclusion"><a class="anchor" href="#_conclusion"></a>7. Conclusion</h2>
<div class="sectionbody">
<div class="paragraph">
<p>They surveyed many interesting papers varying from basic algorithms to more complex ones. When dealing with static geometries and to have an optimized algorithm, the use of top-down construction algorithms using parallelized binning with the SAH-based cost function is recommended for its ease of implementation and the multithreading capabilities alongside SIMD. Significant performance gains can be obtained when combining this method with optimized spatial splits during the construction process, more adapted to handling diagonal, overlapping, or non-uniform-sized primitives. In order to improve the BVH&#8217;s quality, optimization algorithms such as tree rotations, subtree collapsing, or insertion-based optimizations could be used.</p>
</div>
</div>
</div>
</article>
  </div>
</main>
</div>
<footer class="footer" style="border-top: 2px solid #e9e9e9; background-color: #fafafa; padding-bottom: 2em; padding-top: 2em;">
    <div class="container" style="display: flex; flex-direction: column; align-items: center; gap: 0.5em;">
        <div>
            <a href="https://www.cemosis.fr">
                <img src="../_/img/cemosis-logo.svg" alt="Cemosis logo" height="50">
            </a>
        </div>
        <span style="font-size: 0.8rem; color: #9e9e9e">© 2023 <a href="https://www.cemosis.fr" style="text-decoration: underline;">Cemosis</a>, Université de Strasbourg</span>
    </div>
</footer>
<script id="site-script" src="../_/js/site.js" data-ui-root-path="../_"></script>


<script async src="../_/js/vendor/fontawesome-icon-defs.js"></script>
<script async src="../_/js/vendor/fontawesome.js"></script>
<script async src="../_/js/vendor/highlight.js"></script>


<script type="text/javascript">
function toggleFullScreen() {
   var doc = window.document;
   var docEl = doc.documentElement;

   var requestFullScreen = docEl.requestFullscreen || docEl.mozRequestFullScreen || docEl.webkitRequestFullScreen || docEl.msRequestFullscreen;
   var cancelFullScreen = doc.exitFullscreen || doc.mozCancelFullScreen || doc.webkitExitFullscreen || doc.msExitFullscreen;

   if(!doc.fullscreenElement && !doc.mozFullScreenElement && !doc.webkitFullscreenElement && !doc.msFullscreenElement) {
       requestFullScreen.call(docEl);
   }
   else {
       cancelFullScreen.call(doc);
   }
}
</script>
  </body>
</html>
