= Shading Masks computation for solar radiation
:toc: macro

- - -

++++
<br>
<center>
<H1>
	University of Strasbourg <br>
    Master 1 CSMI<br>
    2022-2023<br>
</H1>
</center>
++++

++++
<br>
<center>
<H1>
    Supervisors: Luca Berti, Christophe Prud'homme <br>
</H1>
</center>
<br>
++++

- - -

<<<

toc::[]

== Introduction

=== Context

=== Objectives

During the two months of my internship and under the directives of Luca Berti, my referent, I was in charge of the computation of solar shading masks, weather models and the benchmark of different random number generators. Since this project takes its roots in the 'plan action blablabla emissions CO2', the scale of the computations is substantial as the objective is to compute these at the city level, which involves modeling thousands of households and iterating the same computations over them.

My work can be separated into two quasi-independent parts:

**OPTIMIZATION:**

- Code Vectorization using Eigen library
- Use suitable RNG's for random number generation
- Ray-tracing parallelization using OpenMP 
- Choose a suitable storage strategy for the BVH structure (possibly already choose a good one for NVIDIA's OptiX Ray Tracing API)
- Benchmarking for speed and quality purposes

**IMPLEMENTATION:**

- Solar radiation (heat transfer) code integration
- View factors computation
- Retrieve meteorological data for given longitude and latitude using open-meteo.com
- Rewrite the whole code to be used in the OptiX API enabling strong Ray-Tracing capabilities

=== Tools

==== Global

Seeing the scale of this project, numerous tools will have to be used, ranging from benchmarking simple methods to understanding all the underlyings of compilation flags and optimized data structures for BVH representation of complex and large scenes.

For the benchmarks, libraries such as googletest will be used to perform quality benchmarks on our distributions (speed and quality) and on our BVH construction algorithms such as the traversing ones.

For the strict optimization of the code, especially loops and Random Number Generators, hardware-specific and goal-targeted compilation flags will have to be used, described in their respective sections.

To accelerate the entire process and enable fast computations at city scale, the utilization of GPUs plays a crucial role. GPUs (Graphics Processing Units) are highly parallel processors capable of performing large-scale calculations simultaneously. By harnessing the immense computational power of GPUs, complex and demanding tasks can be accelerated, leading to significant improvements in performance. Their capabilities will be harnessed through the use of CUDA, and will further be accelerated using the OptiX Ray Tracing API disposing of optimized intersection tests, ray generation, and more.

Furthermore, the project can benefit from automation, allowing repetitive tasks to be executed on the Gaya cluster. This automation streamlines the process and maximizes efficiency, enabling rapid iterations and scalability.

During the two-month period, the project also aims to leverage GitHub for maintaining project integrity. This involves utilizing integrated submodules for benchmarking different distributions and effectively managing packages of significant sizes, such as Intel's oneAPI MKL library. Additionally, the project aims to enhance skills in using hardware-optimized SIMD (Single Instruction, Multiple Data) techniques, further optimizing performance and computational efficiency.

==== Parallelization on GPU

The parallelization process on GPUs is a crucial part of this project, but many different architectures exist and hence many different approaches to parallelization are possible. These can be implement in various ways, but different APIs also imply different capabilities and constraints. So depending on the available hardware, different approaches will be used. Below are listed the different APIs that will be used in this project, their advantages and drawbacks, and how they will be used.

===== NVIDIA OptiX 

OptiX is a ray tracing framework developed by NVIDIA. It provides a higher-level programming model specifically designed for ray tracing applications, abstracting away many of the complexities of this technique and providing a simplified interface for developing applications. It handles tasks such as BVH construction, ray traversal, and intersection testing, allowing developers to focus more on the application logic rather than low-level implementation details.

OptiX provides features like programmable shaders (ray generation, closest hit, any hit, miss), support for complex geometry, GPU instancing and built-in acceleration structures. It also integrates with other GPU-accelerated libraries and APIs, such as CUDA and OpenGL, enabling efficient data exchange between different GPU-accelerated tasks.

- BVH Construction: OptiX provides built-in acceleration structure construction algorithms, such as bounding volume hierarchy (BVH) construction. These algorithms are highly optimized and take advantage of the underlying GPU architecture to accelerate the construction process.
- Ray Traversal: OptiX optimizes the ray traversal process by using advanced techniques like stackless traversal and GPU-specific optimizations. These techniques minimize memory accesses and thread divergence, improving performance during the traversal phase.
- Intersection Testing: OptiX allows developers to write custom intersection testing programs using programmable shaders. This flexibility enables the implementation of efficient intersection tests tailored to the specific geometry and shading requirements of the application. More generally, the intersection tests can be performed usiing the built-in method, leveraging the SIMT unit by performing a speculative traversal, where the next state is estimated using probabilities.

In addition to performance optimizations, OptiX also provides parallelization capabilities at several levels : over the GPUs and over the threads, each handling the generation and traversal of one ray, just like it was done in the self-implemented CUDA version. OptiX automatically parallelizes the ray tracing workloads across multiple GPU threads. Each thread processes a different ray, allowing for high levels of parallelism. This parallelization is handled by the OptiX runtime, abstracting away the complexities of parallel programming on the GPU.

OptiX provides a flexible memory management system that allows developers to efficiently manage memory usage during BVH construction and traversal. It provides options to control the memory allocation strategy, such as specifying the maximum amount of memory to be used for the BVH construction, allowing the user to optimize memory consumption based on the available one, which also works when working with GPU clusters.

NVIDIA GPUs use a SIMT (Single Instruction, Multiple Thread) execution model. The SIMT model is similar to SIMD (Single Instruction, Multiple Data) in that it allows executing the same instruction on multiple data elements in parallel. However, SIMT provides more flexibility by allowing threads to follow different execution paths based on conditional statements or data dependencies.

In SIMT, threads are organized into groups called warps, where each warp consists of multiple threads that execute the same instruction. The warp is the basic unit of execution in NVIDIA GPUs, and all threads within a warp execute in lockstep. Each thread within a warp operates on its own data, and the SIMD-like execution happens at the warp level.

While all threads within a warp execute the same instruction, they may diverge based on conditional statements. In such cases, the GPU dynamically partitions the warp into smaller groups, known as active warps, to handle divergent execution paths efficiently. This allows the GPU to hide latency and maximize parallelism by executing other warps while some warps are waiting for conditional branches or memory operations.

Overall, the SIMT execution model in NVIDIA GPUs provides a balance between SIMD-style parallelism and thread-level flexibility, enabling efficient execution of parallel workloads across thousands of threads. 

When coding with the OptiX API, access is granted to optimized methods using speculative traversal methods on the warps, meaning that instead of incrementing the states linearly during traversal, the API will estimate the next state to transfer to, using speculative probabilities in order to optimize the number of threads that can be treated in parallel.

===== CUDA

CUDA is a parallel computing platform and programming model developed by NVIDIA. It allows developers to write high-performance GPU-accelerated code using the CUDA programming language. CUDA provides low-level access to GPU hardware and is suitable for a wide range of general-purpose GPU computing tasks beyond ray tracing.

With CUDA, you have fine-grained control over the GPU and can leverage its parallel processing capabilities for various applications, such as scientific simulations, image and video processing, machine learning, and more.

CUDA allows you to optimize code at a low level and provides flexibility to customize algorithms and data structures based on specific requirements. It is well-suited for those who need fine-grained control over the GPU or want to work with specific GPU features that are not directly exposed by higher-level frameworks like OptiX.
